{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d23a343-3694-45c8-8aa5-771e1cb7c317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9aac4d50-a22d-4223-b32a-be0a31d8cff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Upgrading Tables to Unity Catalog\n",
    "\n",
    "In this demo, you will learn essential techniques for upgrading tables to the Unity Catalog, a pivotal step in efficient data management. This demo will cover various aspects, including analyzing existing data structures, applying migration techniques, evaluating transformation options, and upgrading metadata without moving data. Both SQL commands and user interface (UI) tools will be utilized for seamless upgrades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88d8d10e-18c2-44b4-ba2c-af4dbe0f8678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Learning Objectives\n",
    "By the end of this demo, you will be able to:\n",
    "1. Analyze the current catalog, schema, and table structures in your data environment.\n",
    "2. Execute methods to move data from Hive metastore to Unity Catalog, including cloning and Create Table As Select \\(CTAS\\).\n",
    "3. Assess and apply necessary data transformations during the migration process.\n",
    "4. Utilize methods to upgrade table metadata while keeping data in its original location.\n",
    "5. Perform table upgrades using both SQL commands and user interface tools for efficient data management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28f925ac-d7b1-4613-9fa6-bcfbf19822a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prerequisites\n",
    "In order to follow along with this demo, you will need:\n",
    "* Account administrator capabilities\n",
    "* Cloud resources to support the metastore\n",
    "* Have metastore admin capability in order to create and manage a catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8a6500d-e49f-4833-8de8-2bfd9a0a4c6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "### ---SERVERLESS COMPUTE WILL NOT WORK WITH THE HIVE_METASTORE---\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "  - In the drop-down, select **More**.\n",
    "\n",
    "  - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b02a404-6229-4959-ae26-e07bc0b0d139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course. It will also set your default catalog to your specific catalog and the schema to the schema name shown below using the `USE` statements.\n",
    "<br></br>\n",
    "\n",
    "\n",
    "```\n",
    "USE CATALOG <your catalog>;\n",
    "USE SCHEMA <your catalog>.<schema>;\n",
    "```\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc4d2967-696e-428f-b40b-427a8f10362b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Includes/Classroom-Setup-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66e566ce-e3ba-446a-8a40-c54846d06bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B. Analyze the List of Available Table and Views in the Custom Schema\n",
    "1. Let us analyze the **example** schema within your catalog for the list of tables and views. This has already been set up for you using the setup script. Take note of the tables in your schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a710831f-a5a8-4c51-a65b-76563d8342e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT current_catalog(), current_schema();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5c589a1-d5dc-40a4-aa1e-95a6fcb62474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Show the list of tables within the custom schema\n",
    "SHOW TABLES FROM example;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73afe6fb-10b2-449e-9d0d-19004434f6b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Display a list of views in your **example** schema. Take note of the view(s) in your schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d96dc95-8fe6-483b-8f64-729ac3c3770f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Show the list of views within the custom schema\n",
    "SHOW VIEWS FROM example;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ea51ba7-cbe6-4faf-a385-95bc24f45974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### B. Exploring the Hive Metastore Source Table\n",
    "\n",
    "As part of the setup, we now have a table called *movies*, residing in a user-specific schema of the Hive metastore. To make things easier, the schema name in the hive_metastore stored in a variable named `user_hive_schema` that was created in the classroom setup script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "263bceb0-eded-44a8-9899-c61946a7dc11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- View the value of the user_hive_schema SQL variable\n",
    "SELECT user_hive_schema;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c0cddde-bb8f-4cd4-af06-679516a6f16a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Let's preview the data stored in this table using that variable. Notice how the three-level namespaces makes referencing data objects in the Hive metastore seamless.\n",
    "\n",
    "    Here we will use the `IDENTIFIER()` clause which enables SQL injection safe parameterization of SQL statements and enables you to interprets a constant string as a:\n",
    "    - table or view name\n",
    "    - function name\n",
    "    - column name\n",
    "    - field name\n",
    "\n",
    "    View the [documentation](https://docs.databricks.com/en/sql/language-manual/sql-ref-names-identifier-clause.html#identifier-clause) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb89285f-1ae6-4650-bbe5-8492dcdf884f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "--  Show the first 10 rows from the movies table residing in the user-specific schema of the Hive metastore\n",
    "\n",
    "SELECT * \n",
    "FROM IDENTIFIER('hive_metastore.' || user_hive_schema || '.movies')\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "603ca507-4d97-413b-9661-2b783a17c97b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. Overview of Upgrade Methods\n",
    "\n",
    "There are a few different ways to upgrade a table, but the method you choose will be driven primarily by how you want to treat the table data. If you wish to leave the table data in place, then the resulting upgraded table will be an external table. If you wish to move the table data into your Unity Catalog metastore, then the resulting table will be a managed table. Consult [this page](https://docs.databricks.com/en/data-governance/unity-catalog/index.html#managed-versus-external-tables-and-volumes) for tips on whether to choose a managed or external table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "462409b1-97e0-41a4-be45-5ec1e5f6a1c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C1. Moving Table Data into the Unity Catalog Metastore\n",
    "\n",
    "In this approach, table data will be copied from wherever it resides into the managed data storage area for the destination schema, catalog or metastore. The result will be a managed Delta table in your Unity Catalog metastore. \n",
    "\n",
    "This approach has two main advantages:\n",
    "* Managed tables in Unity Catalog can benefit from product optimization features that may not work well (if at all) on tables that aren't managed\n",
    "* Moving the data also gives you the opportunity to restructure your tables, in case you want to make any changes\n",
    "\n",
    "The main disadvantage to this approach is, particularly for large datasets, the time and cost associated with copying the data.\n",
    "\n",
    "In this section, we cover two different options that will move table data into the Unity Catalog metastore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0b60799-14a0-40d0-be64-34c36932fa45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### C1.1 Cloning a Table\n",
    "\n",
    "Cloning a table is optimal when the source table is Delta (see <a href=\"https://docs.databricks.com/delta/clone.html\" target=\"_blank\">documentation</a> for a full explanation). It's simple to use, it will copy metadata, and it gives you the option of copying data (deep clone) or optionally leaving it in place (shallow clone). Shallow clones can be useful in some use cases.\n",
    "\n",
    "1. Run the following cell to check the format of the source table. View the results. Notice the following:\n",
    "\n",
    "- Referring to the *Provider* row, we see the source is a Delta table. \n",
    "- Referring to the *Location* row, we see that the table is stored in DBFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3ba1312-2361-40bd-b112-cd44e56feab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Describe the properties of the \"movies\" table in the user-specific schema of the Hive metastore using the extended option for more details.\n",
    "-- DESCRIBE EXTENDED hive_metastore.yourschema.movies\n",
    "\n",
    "DESCRIBE EXTENDED IDENTIFIER('hive_metastore.' || user_hive_schema || '.movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7548de96-5fc9-4c1b-9b80-d7a0e41e67d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Let's perform a deep clone operation to copy the table from the hive metastore, creating a destination table named *movies_clone* in the **example** schema with your catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3704098f-6e29-48a6-a949-54971682df38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "## Deep clone the \"movies\" table from the user-specific schema of the Hive metastore to create a new table named \"movies_clone\" in the user-specific catalog of the example schema.\n",
    "\n",
    "results = spark.sql(f'''\n",
    "CREATE OR REPLACE TABLE movies_clone \n",
    "DEEP CLONE hive_metastore.{DA.user_hive_schema}.movies\n",
    "''')\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "250b1cae-3865-41cb-bff8-4554ef268ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Let's manually view our **example** schema within our catalog.\n",
    "    1. Select the catalog icon on the left. \n",
    "\n",
    "    1. Expand your unique catalog name.\n",
    "\n",
    "    1. Expand the **example** schema.\n",
    "\n",
    "    1. Expand **Tables**.\n",
    "\n",
    "    1. Notice that the **movies** table from the hive metastore has been cloned into your schema as **movies_clone**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c3131f6-b0d8-4cfe-b4af-b360fb1beb23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### C1.2 Create Table As Select (CTAS)\n",
    "\n",
    "Using CTAS is a universally applicable technique that simply creates a new table based on the output of a **`SELECT`** statement. This will always copy the data, and no metadata will be copied.\n",
    "\n",
    "1. Let's copy the table from the hive metastore using this approach, creating a destination table named *movies_ctas* in our catalog within the **example** schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d7f629-cf55-4d95-88ca-ebacc6c03e78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Copy the \"movies\" table from the user-specific schema of the Hive metastore to create \"movies_ctas\" in the user-specific catalog's example schema using CTAS (Create Table As Select)\n",
    "\n",
    "CREATE OR REPLACE TABLE movies_ctas AS \n",
    "SELECT * \n",
    "FROM IDENTIFIER('hive_metastore.' || user_hive_schema || '.movies');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24e7c243-5f04-4357-8529-d82addc2609f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Run the `SHOW TABLES` statement to view tables in your **example** schema. Notice that the **movies_ctas** table was created in your catalog from the **movies** table from the hive metastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccd887de-f70e-480f-bad0-d0d86cefd7bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SHOW TABLES IN example;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84291c0e-28f2-4504-b662-23ec0fe58c6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### C1.3 Applying Transformations during the Upgrade\n",
    "\n",
    "CTAS offers an option that other methods do not: the ability to transform the data while copying it.\n",
    "\n",
    "When migrating your tables to Unity Catalog, it's a great time to consider your table structures and whether they still address your organization's business requirements that may have changed over time.\n",
    "\n",
    "Cloning, and the CTAS operation we just saw, takes an exact copy of the source table. But CTAS can be easily adapted to perform any transformations during the upgrade.\n",
    "\n",
    "For example, you could modify the table when migrating it from the hive metastore to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d510158f-c12c-4892-9c26-360bb150a926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Copy the \"movies\" table from Hive metastore to create \"movies_transformed\" in the user-specific catalog using CTAS with the required transformations\n",
    "CREATE OR REPLACE TABLE movies_transformed AS \n",
    "SELECT\n",
    "  id AS Movie_ID,\n",
    "  title AS Movie_Title,\n",
    "  genres AS Genres,\n",
    "  upper(original_language) AS Original_Language,\n",
    "  vote_average AS Vote_Average\n",
    "FROM IDENTIFIER('hive_metastore.' || user_hive_schema || '.movies');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc4b43fe-27c0-40ee-b908-04e0836e5794",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Display the contents of the \"movies_transformed\" table from the user-specific catalog of the example schema\n",
    "SELECT * \n",
    "FROM movies_transformed;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eea5fdc-a5bb-40f7-82c6-939857a1cc46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### C2 Upgrade External Tables in Hive Metastore to External Tables in Unity Catalog\n",
    "\n",
    "**NOTE: This lab environment does not have access to external tables. This is an example of what you can do in your environment.**\n",
    "\n",
    "We have seen approaches that involve moving table data from wherever it is currently to the Unity Catalog metastore. However, in upgrading external tables, some use cases may call for leaving the data in place. For example:\n",
    "* Data location is dictated by an internal or regulatory requirement of some sort\n",
    "* Cannot change the data format to Delta\n",
    "* Outside writers must be able to modify the data\n",
    "* Avoiding time and/or cost of moving large datasets\n",
    "\n",
    "Note the following constraints for this approach:\n",
    "\n",
    "* Source table must be an external table\n",
    "* There must be a storage credential referencing the storage container where the source table data resides\n",
    "\n",
    "In this section, we cover two different options that will upgrade to an external table without moving any table data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c92ef0d8-0747-470e-a2c4-559c79e3e5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### C2.1 Using SYNC to Export Hive External Tables to Unity Catalog\n",
    "\n",
    "The **`SYNC`** SQL command allows us to upgrade **external tables** in Hive Metastore to **external tables** in Unity Catalog.\n",
    "\n",
    "For more information on the [SYNC statement](https://docs.databricks.com/en/sql/language-manual/sql-ref-syntax-aux-sync.html#sync) view the documentation.\n",
    "\n",
    "**NOTE:** This lab workspace does not enable you to create external tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "266c683c-22de-4fea-82ad-bc336f14f66f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### C2.2 Using Catalog Explorer to Upgrade Tables to Unity Catalog from the Hive Metastore\n",
    "\n",
    "Let's try upgrading the table using the Catalog Explorer user interface.\n",
    "\n",
    "1. Select the catalog icon on the left.\n",
    "\n",
    "1. Expand the **hive_metastore**.\n",
    "\n",
    "1. Expand your schema name in the hive metastore.\n",
    "\n",
    "1. Right click on your schema name and select **Open in Catalog Explorer**.\n",
    "\n",
    "1. Select the **movies** table \\(it can be any available table\\).\n",
    "\n",
    "1. Click **Upgrade**.\n",
    "\n",
    "1. Select your destination catalog and schema. \n",
    "\n",
    "1. For **Select catalog** select your unique catalog name.\n",
    "\n",
    "1. For **Select schema** select the **example** schema.\n",
    "\n",
    "1. For this example, let's leave owner set to the default (your username).\n",
    "\n",
    "1. Click **Next**.\n",
    "\n",
    "From here you can run the upgrade, or open a notebook containing the upgrade operations that you can run interactively. For the purpose of the exercise, you don't need to actually run the upgrade since it uses `SYNC` behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea51f27a-dd3d-470b-a940-7178d121a5fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## CleanUp\n",
    "Lets quickly clean up the data in hive metastore by running below command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13104478-c470-4e74-b431-54a7f9cc82bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%py\n",
    "DA.cleanup_hive_metastore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02f4629a-2b90-4b36-a430-760ad160e0ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Conclusion\n",
    "In this demo, we explored crucial techniques for upgrading tables to the Unity Catalog, focusing on efficient data management. We learned to analyze existing data structures, apply migration techniques, evaluate transformation options, and upgrade metadata without moving data. Through SQL commands and user interface tools, we seamlessly executed upgrades, considering the treatment of table data as either external or managed within the Unity Catalog. With a thorough understanding of these methods, you are now equipped to optimize your data management processes effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d7a5ac2-e8ea-4a03-8c77-cae4d31d0f0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the \n",
    "<a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "sql",
   "notebookMetadata": {},
   "notebookName": "3 - Upgrading Tables to Unity Catalog",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}